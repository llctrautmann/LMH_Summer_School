{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models,transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "def mnist(batch_sz, valid_size=0.2, shuffle=True, random_seed=2000):\n",
    "    num_classes = 10\n",
    "    transform_train = transforms.Compose([\n",
    "                        transforms.RandomCrop(28, padding=4),\n",
    "                        transforms.ToTensor(),\n",
    "                    ])\n",
    "    \n",
    "    transform_valid = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                    ])\n",
    "    \n",
    "    transform_test = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                    ])\n",
    "    \n",
    "\n",
    "    # Training dataset\n",
    "    train_data = MNIST(root='./datasets', train=True, download=True, transform=transform_train)\n",
    "    valid_data = MNIST(root='./datasets', train=True, download=True, transform=transform_valid)\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    if shuffle == True:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_sz, sampler=train_sampler,pin_memory=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_sz, sampler=valid_sampler,pin_memory=True)\n",
    "\n",
    "    # Test dataset\n",
    "    test_data = MNIST(root='./datasets', train=False, download=True, transform=transform_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                              batch_size=batch_sz, shuffle=False, pin_memory=True)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz=64 # this is batch size i.e. the number of rows in a batch of data\n",
    "train_loader, valid_loader, test_loader=mnist(batch_sz) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR10\n",
    "def cifar10(batch_sz, path='./datasets'):\n",
    "    num_classes = 10\n",
    "    transform_train = transforms.Compose([\n",
    "                        transforms.RandomCrop(32, padding=4),\n",
    "                        transforms.RandomHorizontalFlip(),\n",
    "                        transforms.ToTensor(),\n",
    "                    ])\n",
    "    transform_test = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                    ])\n",
    "\n",
    "    # Training dataset\n",
    "    train_data = CIFAR10(root=path, train=True, download=True, transform=transform_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_sz,\n",
    "                                               shuffle=True, pin_memory=True)\n",
    "\n",
    "    # Test dataset\n",
    "    test_data = CIFAR10(root=path, train=False, download=True, transform=transform_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                              batch_size=batch_sz, shuffle=False, pin_memory=True)\n",
    "\n",
    "    return train_loader, test_loader, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/CNN/CNN_3Channels.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/CNN/CNN_3Channels.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m batch_sz\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m \u001b[39m# this is batch size i.e. the number of rows in a batch of data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/CNN/CNN_3Channels.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_loader, valid_loader, test_loader\u001b[39m=\u001b[39mmnist(batch_sz)\n",
      "\u001b[1;32m/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/CNN/CNN_3Channels.ipynb Cell 6\u001b[0m in \u001b[0;36mmnist\u001b[0;34m(batch_sz, valid_size, shuffle, random_seed)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/CNN/CNN_3Channels.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmnist\u001b[39m(batch_sz, valid_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_seed\u001b[39m=\u001b[39m\u001b[39m2000\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/CNN/CNN_3Channels.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     num_classes \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/CNN/CNN_3Channels.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     transform_train \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/CNN/CNN_3Channels.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                         transforms\u001b[39m.\u001b[39mRandomCrop(\u001b[39m28\u001b[39m, padding\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/CNN/CNN_3Channels.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                         transforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/CNN/CNN_3Channels.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                     ])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/CNN/CNN_3Channels.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     transform_valid \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/CNN/CNN_3Channels.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                         transforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/CNN/CNN_3Channels.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                     ])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/CNN/CNN_3Channels.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     transform_test \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/CNN/CNN_3Channels.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                         transforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/CNN/CNN_3Channels.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m                     ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "batch_sz=64 # this is batch size i.e. the number of rows in a batch of data\n",
    "train_loader, valid_loader, test_loader=mnist(batch_sz) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels=1) -> None:\n",
    "        super(CNN,self).__init__() # In the other tutorial he is using CNN and self within the super(CNN, self) brakets\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size= (2,2), stride= (2,2))\n",
    "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
    "\n",
    "        self._in = nn.Linear(16*7*7, 512)\n",
    "        self.h1 = nn.Linear(512,256)\n",
    "        self.h2 = nn.Linear(256,128)\n",
    "        self.lin_out = nn.Linear(128,10)\n",
    "\n",
    "\n",
    "    # Forward Pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.maxpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "\n",
    "        x = torch.relu(self._in(x))\n",
    "        x = torch.relu(self.h1(x))\n",
    "        x = torch.relu(self.h2(x))\n",
    "        x = self.lin_out(x)\n",
    "            \n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Summer_School",
   "language": "python",
   "name": "summer_school"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d410fd81c9a0b51d0e53167c40a880776428168a003798fed6e3e9082ee009aa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
