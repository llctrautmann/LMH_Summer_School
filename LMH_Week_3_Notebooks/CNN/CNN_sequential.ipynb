{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models,transforms\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchsummary import summary\n",
    "\n",
    "torch.set_printoptions(linewidth=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "def mnist(batch_sz, valid_size=0.2, shuffle=True, random_seed=2000):\n",
    "    num_classes = 10\n",
    "    transform_train = transforms.Compose([\n",
    "                        transforms.RandomCrop(28, padding=4),\n",
    "                        transforms.ToTensor(),\n",
    "                    ])\n",
    "    \n",
    "    transform_valid = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                    ])\n",
    "    \n",
    "    transform_test = transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                    ])\n",
    "    \n",
    "\n",
    "    # Training dataset\n",
    "    train_data = MNIST(root='./datasets', train=True, download=True, transform=transform_train)\n",
    "    valid_data = MNIST(root='./datasets', train=True, download=True, transform=transform_valid)\n",
    "    num_train = len(train_data)\n",
    "    indices = list(range(num_train))\n",
    "    split = int(np.floor(valid_size * num_train))\n",
    "    if shuffle == True:\n",
    "        np.random.seed(random_seed)\n",
    "        np.random.shuffle(indices)\n",
    "    train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_sz, sampler=train_sampler,pin_memory=True)\n",
    "    valid_loader = torch.utils.data.DataLoader(valid_data, batch_size=batch_sz, sampler=valid_sampler,pin_memory=True)\n",
    "\n",
    "    # Test dataset\n",
    "    test_data = MNIST(root='./datasets', train=False, download=True, transform=transform_test)\n",
    "    test_loader = torch.utils.data.DataLoader(test_data,\n",
    "                                              batch_size=batch_sz, shuffle=False, pin_memory=True)\n",
    "\n",
    "    return train_loader, valid_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz=64 # this is batch size i.e. the number of rows in a batch of data\n",
    "train_loader, valid_loader, test_loader=mnist(batch_sz) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNet(nn.Module):\n",
    "    def __init__(self, input_size, output_size=10, no_hidden_layers=10,hidden_layer_size=512) -> None:\n",
    "        super(NNet,self).__init__()\n",
    "        self.deep_nn = nn.Sequential()\n",
    "        \n",
    "        for i in range(no_hidden_layers):\n",
    "            self.deep_nn.add_module(f'ff{i}', nn.Linear(input_size,hidden_layer_size))\n",
    "            self.deep_nn.add_module(f'activation{i}',nn.ReLU())\n",
    "            input_size = hidden_layer_size\n",
    "\n",
    "        self.deep_nn.add_module(f'classifier',nn.Linear(hidden_layer_size,output_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        tensor = self.deep_nn(x)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn(64,1,28,28)\n",
    "# x = x.reshape(x.shape[0],-1)\n",
    "\n",
    "# print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NNet(784).to(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "\n",
    "# input_size = 784\n",
    "# lr = 1e-3\n",
    "# mm = 0.5\n",
    "# epoch = 100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTraining:\n",
    "    def __init__(self,input_size,epoch=100,learning_rate = 1e-3, momentum = 0.5) -> None:\n",
    "        self._in_size = input_size\n",
    "        self._lr = learning_rate\n",
    "        self._mm = momentum \n",
    "        self._epoch = epoch\n",
    "\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.optimizer = optim.SGD(model.parameters(), lr=self._lr, momentum= self._mm)\n",
    "        self.lr_scheduler = optim.lr_scheduler.ExponentialLR(self.optimizer,gamma=0.9,verbose=True)\n",
    "\n",
    "\n",
    "        # outputs\n",
    "\n",
    "        self.loss = list()\n",
    "        self.accuracy = list()\n",
    "\n",
    "\n",
    "\n",
    "    def training(self):\n",
    "        for i in range(self._epoch):\n",
    "            total_loss = 0\n",
    "            total_accuracy = 0\n",
    "            total_train = 0\n",
    "            for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "                data = data.to(device=device)\n",
    "                targets = targets.to(device=device)\n",
    "\n",
    "                data = data.reshape(data.shape[0],-1)\n",
    "\n",
    "                # forwards\n",
    "                logits = model(data)\n",
    "                loss = self.criterion(logits, targets)\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # gradient decent\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                out = torch.argmax(logits, dim=1)\n",
    "                total_accuracy += torch.sum(out == targets)\n",
    "                total_train += logits.shape[0]\n",
    "\n",
    "            self.loss.append(total_loss)\n",
    "\n",
    "        return 'Model Training completed!'\n",
    "\n",
    "    def output(self):\n",
    "        return self.loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ModelTraining(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = output.training()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Summer_School",
   "language": "python",
   "name": "summer_school"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
