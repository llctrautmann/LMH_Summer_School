{"cells":[{"cell_type":"markdown","metadata":{"id":"k42VjJpwBmFO"},"source":["##Data Augmentation\n","\n","In most DL applications Data is one of the major bottlenecks it is not always easy to collect and lable data. We are always looking for smart ways to reduce the cost of data generation.\n","\n","One way to do this data augmentaion, where we use the available data to produce more data samples.\n","\n","In this example we will generate new samples of MNIST dataset using torchvision.transforms.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ogERiTHyabo6"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torchvision.utils import make_grid\n","from torchvision.utils import save_image\n","from torchvision import transforms\n","from torchvision.datasets import MNIST\n","from torch.utils.data import Dataset, DataLoader\n","import imageio as Image\n","from skimage import transform\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0ms7Y9L-ajhY"},"outputs":[],"source":["\n","\n","\n","# MNIST\n","def mnist(batch_sz):\n","    num_classes = 10\n","    transform_train = transforms.Compose([\n","                        transforms.RandomCrop(28, padding=4),\n","                        transforms.ToTensor(),\n","                    ])\n","    transform_test = transforms.Compose([\n","                        transforms.ToTensor(),\n","                    ])\n","\n","    # Training dataset\n","    train_data = MNIST(root='./datasets', train=True, download=True, transform=transform_train)\n","    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_sz, shuffle=True,pin_memory=True)\n","\n","    # Test dataset\n","    test_data = MNIST(root='./datasets', train=False, download=True, transform=transform_test)\n","    test_loader = torch.utils.data.DataLoader(test_data,\n","                                              batch_size=batch_sz, shuffle=False, pin_memory=True)\n","\n","    return train_loader, test_loader, num_classes\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hl216TR5anuS"},"outputs":[],"source":["train_loader, test_loader,_=mnist(10)"]},{"cell_type":"markdown","metadata":{"id":"93wkfsWopZ_4"},"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a6fvkSXOarUD"},"outputs":[],"source":["!mkdir 'images'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Po7h5QFXatxL"},"outputs":[],"source":["\n","\n","im_name=[]\n","labels=[]\n","for i,batch in enumerate(train_loader):\n","  ind=0\n","  if i>30:\n","      break\n","  for j in range(batch[0].shape[0]):\n","    \n","    im=batch[0][j,:,:,:]\n","    save_image(im,f\"./images/{ind}.jpg\",normalize=True)\n","    im_name.append(f\"{ind}.jpg\")\n","    labels.append(batch[1][j].item())\n","    ind+=1\n","    im=torch.squeeze(im)\n","\n","    #plt.imshow(im)\n","    #plt.title(f\"{batch[1][j].item()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wdJ4N2f0aw0g"},"outputs":[],"source":["import pandas as pd\n","df=pd.DataFrame(zip(im_name,labels),columns=['Name','label'])\n","\n","df.to_csv('im_list.csv')"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Seminar6_Augmentation.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}