{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_mMw1jKdhNI"
      },
      "source": [
        "Perform CIFAR10 classification using Neural Netwroks and Convolutional Neural Networks.\n",
        "\n",
        "1) Use 10 iterations for training\n",
        "\n",
        "\n",
        "2) Show the training loss for both networks on the same plot\n",
        "\n",
        "\n",
        "3) Compare the test loss and accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "FD6fwO1ddbEU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import models,transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "L6xbtkeiecRm"
      },
      "outputs": [],
      "source": [
        "# CIFAR10\n",
        "def cifar10(batch_sz, path='./datasets'):\n",
        "    num_classes = 10\n",
        "    transform_train = transforms.Compose([\n",
        "                        transforms.RandomCrop(32, padding=4), # Increase the number of samples by moving the images around \n",
        "                        transforms.RandomHorizontalFlip(),\n",
        "                        transforms.ToTensor(),\n",
        "                    ])\n",
        "    transform_test = transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                    ])\n",
        "\n",
        "    # Training dataset\n",
        "    train_data = CIFAR10(root=path, train=True, download=True, transform=transform_train) # \n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_sz,\n",
        "                                               shuffle=True, pin_memory=True)\n",
        "\n",
        "    # Test dataset\n",
        "    test_data = CIFAR10(root=path, train=False, download=True, transform=transform_test)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data,\n",
        "                                              batch_size=batch_sz, shuffle=False, pin_memory=True)\n",
        "\n",
        "    return train_loader, test_loader, num_classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "u3fKOo5negms"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "batch_sz=64 # this is batch size i.e. the number of rows in a batch of data\n",
        "train_loader, test_loader, _=cifar10(batch_sz) \n",
        "\n",
        "tl = iter(train_loader)\n",
        "batch = next(tl)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "def show_image(batch,img):\n",
        "    return plt.imshow(np.transpose(batch[0][img,:,:,:],(1,2,0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the Class \n",
        "\n",
        "\n",
        "# CNN\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels=3,num_classes=10) -> None:\n",
        "        super(CNN,self).__init__() # In the other tutorial he is using CNN and self within the super(CNN, self) brakets\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3,3),stride=(1,1),padding=(1,1))  #  3 -1 /2 ; 3 being the filter_size, with padding the image size stays the same\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
        "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
        "        self.conv5 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=(3,3),stride=(1,1),padding=(1,1)) # this is not useful\n",
        "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=(3,3),stride=(1,1),padding=(1,1))\n",
        "\n",
        "\n",
        "\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size= (2,2), stride= (2,2))\n",
        "\n",
        "        self._in = nn.Linear(64*4*4, 1024)\n",
        "        self.h1 = nn.Linear(1024,512) # remove and adjust dims to recover AC2\n",
        "        self.h2 = nn.Linear(512,256)\n",
        "        self.h3 = nn.Linear(256,128)\n",
        "        self.lin_out = nn.Linear(128,num_classes) # change 128 to 16*7*7 for AC1\n",
        "\n",
        "\n",
        "    # Forward Pass\n",
        "    \n",
        "    def forward(self, x):\n",
        "\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = torch.relu(self.conv3(x))\n",
        "        x = torch.relu(self.conv4(x))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = torch.relu(self.conv5(x))\n",
        "        x = torch.relu(self.conv6(x))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # Linear Model\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = torch.relu(self._in(x))\n",
        "        x = torch.relu(self.h1(x))\n",
        "        x = torch.relu(self.h2(x))\n",
        "        x = torch.relu(self.h3(x))\n",
        "        x = self.lin_out(x)\n",
        "            \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dim test\n",
        "\n",
        "def dim_test(model,dim,channel,x1,x2):\n",
        "    model = model.to(device=device)\n",
        "    x = torch.randn(dim,channel,x1,x2)\n",
        "    return model(x).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 10])"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dim_test(Cifar10CnnModel(),64,3,32,32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Hyperparameter\n",
        "\n",
        "inputs = 3*32*32\n",
        "mm = 0\n",
        "batch_sz=64\n",
        "epoch_no = 3\n",
        "mini_batches = [64]\n",
        "learning_rates = [0.05,0.01,0.005]\n",
        "learning_rates = learning_rates[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [],
      "source": [
        "def var_training(model=CNN(),type_CNN = True):\n",
        "    for mini_batch in mini_batches:\n",
        "        for learning_rate in learning_rates:\n",
        "            model_2 = model.to(device=device)\n",
        "        \n",
        "            # write to tensorboard\n",
        "            step = 0\n",
        "\n",
        "            if type_CNN == True:\n",
        "                writer = SummaryWriter(f'runs/CIFAR10/CNN_minibatch={mini_batch}_learning_rate={learning_rate}')\n",
        "            else:\n",
        "                model = input()\n",
        "                writer = SummaryWriter(f'runs/CIFAR10/{model}_minibatch={mini_batch}_learning_rate={learning_rate}')\n",
        "\n",
        "\n",
        "            # Loss and optimizer\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            optimizer = optim.SGD(model_2.parameters(), lr=learning_rate, momentum= mm)\n",
        "            scheduler = None\n",
        "\n",
        "            # generate new data\n",
        "            train_loader, test_loader, _=cifar10(mini_batch) \n",
        "\n",
        "            \n",
        "            \n",
        "            for epoch in range(epoch_no):\n",
        "                train_loss = 0\n",
        "                for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "                    data = data.to(device=device)\n",
        "                    targets = targets.to(device=device)\n",
        "\n",
        "                    if type_CNN == False:\n",
        "                        data = data.reshape(data.shape[0], -1)\n",
        "                    else:\n",
        "                        pass\n",
        "\n",
        "                    # forwards\n",
        "                    logits = model_2(data)\n",
        "                    loss = criterion(logits, targets)\n",
        "                    train_loss += loss.item()\n",
        "\n",
        "\n",
        "                    # backward \n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "                    # scbeduler.step()\n",
        "\n",
        "                    # Running Accuracy\n",
        "                    _, predictions = logits.max(1)\n",
        "                    num_corr = (predictions == targets).sum()\n",
        "                    running_acc = float(num_corr)/float(data.shape[0])\n",
        "                    \n",
        "                    writer.add_scalar(\"Training Loss\", loss, global_step = step) \n",
        "                    writer.add_scalar(\"Accuracy\", running_acc, global_step=step)\n",
        "                    step += 1  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/Homework/HW3_2.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/Homework/HW3_2.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m var_training(model\u001b[39m=\u001b[39;49mCifar10CnnModel(),type_CNN\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[1;32m/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/Homework/HW3_2.ipynb Cell 12\u001b[0m in \u001b[0;36mvar_training\u001b[0;34m(model, type_CNN)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/Homework/HW3_2.ipynb#X46sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# backward \u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/Homework/HW3_2.ipynb#X46sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/Homework/HW3_2.ipynb#X46sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/Homework/HW3_2.ipynb#X46sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/Homework/HW3_2.ipynb#X46sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# scbeduler.step()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/Homework/HW3_2.ipynb#X46sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/Oxford_Summer_School/LMH_Week_3_Notebooks/Homework/HW3_2.ipynb#X46sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39m# Running Accuracy\u001b[39;00m\n",
            "File \u001b[0;32m~/.pyenv/versions/Summer_School/lib/python3.10/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
            "File \u001b[0;32m~/.pyenv/versions/Summer_School/lib/python3.10/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "var_training(model=,type_CNN=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "            x = x.reshape(x.shape[0], -1)\n",
        "\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "    model.train()\n",
        "    return num_correct/num_samples\n",
        "\n",
        "\n",
        "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\n",
        "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "HW3_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Summer_School",
      "language": "python",
      "name": "summer_school"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "d410fd81c9a0b51d0e53167c40a880776428168a003798fed6e3e9082ee009aa"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
