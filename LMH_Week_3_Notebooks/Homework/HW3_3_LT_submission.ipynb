{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_mMw1jKdhNI"
      },
      "source": [
        "Perform CIFAR10 classification using ResNet18.\n",
        "\n",
        "1) Train ResNet18 from Scratch\n",
        "\n",
        "\n",
        "2) Finetune ResNet from Pretarined network on ImageNet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FD6fwO1ddbEU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a11d104-5959-48ad-bd08-2a9cfc64e5b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 30.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.9.3\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import models,transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchsummary import summary\n",
        "import torchmetrics as tm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "L6xbtkeiecRm"
      },
      "outputs": [],
      "source": [
        "# CIFAR10\n",
        "def cifar10(batch_sz, path='./datasets'):\n",
        "    num_classes = 10\n",
        "    transform_train = transforms.Compose([\n",
        "                        transforms.RandomCrop(32, padding=4),\n",
        "                        transforms.RandomHorizontalFlip(),\n",
        "                        transforms.ToTensor(),\n",
        "                    ])\n",
        "    transform_test = transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                    ])\n",
        "\n",
        "    # Training dataset\n",
        "    train_data = CIFAR10(root=path, train=True, download=True, transform=transform_train)\n",
        "    train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_sz,\n",
        "                                               shuffle=True, pin_memory=True)\n",
        "\n",
        "    # Test dataset\n",
        "    test_data = CIFAR10(root=path, train=False, download=True, transform=transform_test)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data,\n",
        "                                              batch_size=batch_sz, shuffle=False, pin_memory=True)\n",
        "\n",
        "    return train_loader, test_loader, num_classes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "u3fKOo5negms",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aded54ed-c24d-41f8-f642-c0229f85c98d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "batch_sz=64 # this is batch size i.e. the number of rows in a batch of data\n",
        "train_loader, test_loader, _=cifar10(batch_sz) "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet18(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py96O5f8VpFb",
        "outputId": "f9fbc851-eb11-430f-a78f-7687dc615137"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
            "  f\"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, \"\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ft5m1nYgnJYu",
        "outputId": "ef9ae040-c35d-421e-b4d8-86c28fd15653"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fc == nn.Linear(in_features=512, out_features=10, bias=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGI7mdM3mlPL",
        "outputId": "02c1f518-3343-4639-dbf0-676f5abae8ba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter\n",
        "\n",
        "learning_rate = 1e-3\n",
        "mm = 0\n",
        "batch_sz=512\n",
        "epoch_no = 10\n",
        "\n"
      ],
      "metadata": {
        "id": "KyRYKLDRVpk9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model.to(device=device)\n",
        "\n",
        "# write to tensorboard\n",
        "step = 0\n",
        "writer = SummaryWriter(f'runs/ResNet/bs={batch_sz}_lr={learning_rate}')\n",
        "\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum= mm)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer=optimizer,gamma=0.9,verbose=False)\n",
        "\n",
        "for epoch in range(epoch_no):\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        # forwards\n",
        "        logits = model(data)\n",
        "        loss = criterion(logits, targets)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "\n",
        "        # backward \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        # scheduler.step()\n",
        "\n",
        "        # Running Accuracy\n",
        "        _, predictions = logits.max(1)\n",
        "        num_corr = (predictions == targets).sum()\n",
        "        running_acc = float(num_corr)/float(data.shape[0])\n",
        "        \n",
        "        writer.add_scalar(\"Training Loss\", loss, global_step = step) \n",
        "        writer.add_scalar(\"Training Accuracy\", running_acc, global_step=step)\n",
        "        step += 1  \n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "acc_l = []\n",
        "\n",
        "accuracy = tm.Accuracy()\n",
        "\n",
        "with torch.no_grad():\n",
        "    step_2 = 0\n",
        "    for batch_idx, (data, targets) in enumerate(test_loader):\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        logits = model(data)\n",
        "        t_loss = criterion(logits, targets)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        yhat = torch.argmax(logits, axis =1)\n",
        "\n",
        "        acc = accuracy(yhat.to(\"cpu\"),targets.to(\"cpu\"))\n",
        "\n",
        "        acc_l.append(acc)\n",
        "\n",
        "        writer.add_scalar(\"Testing Loss\", t_loss, global_step = step_2) \n",
        "        writer.add_scalar(\"Testing Accuracy\", acc, global_step=step_2)\n",
        "        step_2 += 1\n",
        "\n",
        "print(f'the accuracy on the test set for the batch size: {batch_sz} and learning rate: {learning_rate} is {np.mean(acc_l):.2f}')"
      ],
      "metadata": {
        "id": "n0fy4eYNmXz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QbDd2ZCdsAc7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "HW3_3_LT_submission.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.3 64-bit ('3.10.3')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "d410fd81c9a0b51d0e53167c40a880776428168a003798fed6e3e9082ee009aa"
      }
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}